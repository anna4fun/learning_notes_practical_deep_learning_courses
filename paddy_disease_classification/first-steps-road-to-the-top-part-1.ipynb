{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":35325,"databundleVersionId":3359805,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys, timm, torch\nprint(sys.version)\nprint(timm.__version__)\nprint(torch.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T16:42:42.174468Z","iopub.execute_input":"2025-08-20T16:42:42.175039Z","iopub.status.idle":"2025-08-20T16:42:53.242470Z","shell.execute_reply.started":"2025-08-20T16:42:42.175012Z","shell.execute_reply":"2025-08-20T16:42:53.241661Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# install fastkaggle if not available\ntry: import fastkaggle\nexcept ModuleNotFoundError:\n    !pip install -Uq fastkaggle\n\nfrom fastkaggle import *","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T16:42:53.243549Z","iopub.execute_input":"2025-08-20T16:42:53.244211Z","iopub.status.idle":"2025-08-20T16:42:57.631403Z","shell.execute_reply.started":"2025-08-20T16:42:53.244191Z","shell.execute_reply":"2025-08-20T16:42:57.630475Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In [Iterate Like a Grandmaster](https://www.kaggle.com/code/jhoward/iterate-like-a-grandmaster) I explained that when working on a Kaggle project:\n\n> ...the focus generally should be two things:\n> \n> 1. Creating an effective validation set\n> 2. Iterating rapidly to find changes which improve results on the validation set.\n\nHere I'm going to go further, showing the process I used to tackle the [Paddy Doctor](https://www.kaggle.com/competitions/paddy-disease-classification) competition, leading to four submissions in a row which all were (at the time of submission) in 1st place, each one more accurate than the last. You might be surprised to discover that the process of doing this was nearly entirely mechanistic and didn't involve any consideration of the actual data or evaluation details at all.\n\nThis notebook is the first in a series showing every step of the process. At the end of this notebook we'll have a basic submission; by the end of the series you'll see how I got to the top of the table!:\n\n<img src=\"https://user-images.githubusercontent.com/346999/174389920-60d67ead-0f36-41d0-9649-e23b08720c8a.png\" width=\"600\"/>","metadata":{}},{"cell_type":"markdown","source":"As a special extra, I'm also opening up early a selection of \"walkthru\" videos that we've been preparing for the new upcoming fast.ai course. Each day I do a walkthru with fast.ai fellows and registered students, and we record those sessions. They'll all be released at the same time as the next course (probably August 2022), but I'm releasing the ones covering this competition right now! Here they are:\n\n- [Walkthru 8](https://www.youtube.com/watch?v=-Scs4gbwWXg)\n- [Walkthru 9](https://www.youtube.com/watch?v=EK5wJRzffas)\n- [Walkthru 10](https://youtu.be/zhBRynq9Yvo)\n- [Walkthru 11](https://youtu.be/j-zMF2VirA8)\n- [Walkthru 12](https://youtu.be/GuCkpjXHdTc)\n- [Walkthru 13](https://youtu.be/INrkhUGCXHg)\n\nWhen you're done with this notebook, take a look at [part 2 of the series](https://www.kaggle.com/code/jhoward/small-models-road-to-the-top-part-2/).","metadata":{}},{"cell_type":"markdown","source":"## Getting set up","metadata":{}},{"cell_type":"markdown","source":"First, we'll get the data. I've just created a new library called [fastkaggle](https://fastai.github.io/fastkaggle/) which has a few handy features, including getting the data for a competition correctly regardless of whether we're running on Kaggle or elsewhere. Note you'll need to first accept the competition rules and join the competition, and you'll need your kaggle API key file `kaggle.json` downloaded if you're running this somewhere other than on Kaggle. `setup_comp` is the function we use in `fastkaggle` to grab the data, and install or upgrade our needed python modules when we're running on Kaggle:","metadata":{}},{"cell_type":"code","source":"comp = 'paddy-disease-classification'\n\npath = setup_comp(comp) #, install='fastai \"timm>=0.6.2.dev0\"')","metadata":{"_kg_hide-output":true,"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T16:47:44.344914Z","iopub.execute_input":"2025-08-20T16:47:44.345562Z","iopub.status.idle":"2025-08-20T16:47:44.349272Z","shell.execute_reply.started":"2025-08-20T16:47:44.345536Z","shell.execute_reply":"2025-08-20T16:47:44.348582Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T16:47:45.218322Z","iopub.execute_input":"2025-08-20T16:47:45.218964Z","iopub.status.idle":"2025-08-20T16:47:45.225250Z","shell.execute_reply.started":"2025-08-20T16:47:45.218931Z","shell.execute_reply":"2025-08-20T16:47:45.224560Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now we can import the stuff we'll need from fastai, set a seed (for reproducibility -- just for the purposes of making this notebook easier to write; I don't recommend doing that in your own analysis however) and check what's in the data:","metadata":{}},{"cell_type":"code","source":"from fastai.vision.all import *\n# set_seed(42)\n\npath.ls()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T16:47:49.446139Z","iopub.execute_input":"2025-08-20T16:47:49.446445Z","iopub.status.idle":"2025-08-20T16:47:51.066209Z","shell.execute_reply.started":"2025-08-20T16:47:49.446395Z","shell.execute_reply":"2025-08-20T16:47:51.065458Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Looking at the data","metadata":{}},{"cell_type":"markdown","source":"The images are in `train_images`, there're 10 folders under `train_images` with the folder name as the name of the disease, so let's grab a list of all of them:","metadata":{}},{"cell_type":"code","source":"trn_path = path/'train_images'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T16:52:50.840601Z","iopub.execute_input":"2025-08-20T16:52:50.841357Z","iopub.status.idle":"2025-08-20T16:52:50.845252Z","shell.execute_reply.started":"2025-08-20T16:52:50.841328Z","shell.execute_reply":"2025-08-20T16:52:50.844403Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trn_path.ls()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T16:53:07.048916Z","iopub.execute_input":"2025-08-20T16:53:07.049197Z","iopub.status.idle":"2025-08-20T16:53:07.056382Z","shell.execute_reply.started":"2025-08-20T16:53:07.049173Z","shell.execute_reply":"2025-08-20T16:53:07.055688Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_files = get_image_files(trn_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:04:35.392578Z","iopub.execute_input":"2025-08-20T17:04:35.392855Z","iopub.status.idle":"2025-08-20T17:04:40.858767Z","shell.execute_reply.started":"2025-08-20T17:04:35.392835Z","shell.execute_reply":"2025-08-20T17:04:40.857989Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type(train_files)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:10:30.869006Z","iopub.execute_input":"2025-08-20T17:10:30.869786Z","iopub.status.idle":"2025-08-20T17:10:30.875068Z","shell.execute_reply.started":"2025-08-20T17:10:30.869747Z","shell.execute_reply":"2025-08-20T17:10:30.874360Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"...and take a look at one:","metadata":{}},{"cell_type":"code","source":"img = PILImage.create(train_files[20])\nprint(img.size)\nimg.to_thumb(128)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:04:43.368948Z","iopub.execute_input":"2025-08-20T17:04:43.369217Z","iopub.status.idle":"2025-08-20T17:04:43.390195Z","shell.execute_reply.started":"2025-08-20T17:04:43.369196Z","shell.execute_reply":"2025-08-20T17:04:43.389471Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type(img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:03:24.301459Z","iopub.execute_input":"2025-08-20T17:03:24.301988Z","iopub.status.idle":"2025-08-20T17:03:24.306868Z","shell.execute_reply.started":"2025-08-20T17:03:24.301964Z","shell.execute_reply":"2025-08-20T17:03:24.306182Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Looks like the images might be 480x640 -- let's check all their sizes. This is faster if we do it in parallel, so we'll use fastcore's `parallel` for this:\n\n```\nFunction:\nparallel(f, items, *args, n_workers=4, total=None, progress=None,\n           pause=0, method=None, threadpool=False, timeout=None,\n           chunksize=1, **kwargs)\n```\n* What this does: Applies func in parallel to items, using n_workers \n","metadata":{}},{"cell_type":"code","source":"from fastcore.parallel import *\n\ndef file_size(o): return PILImage.create(o).size\n    \nsizes = parallel(file_size, train_files, n_workers=10) # apply file_size function to all items under folder train_files, parallel to 10 workers\npd.Series(sizes).value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:05:27.039219Z","iopub.execute_input":"2025-08-20T17:05:27.039529Z","iopub.status.idle":"2025-08-20T17:05:50.136711Z","shell.execute_reply.started":"2025-08-20T17:05:27.039508Z","shell.execute_reply":"2025-08-20T17:05:50.135914Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"They're nearly all the same size, except for a few. Because of those few, however, we'll need to make sure we always resize each image to common dimensions first, otherwise fastai won't be able to create batches. For now, we'll just squish them to 480x480 images, and then once they're in batches we do a random resized crop down to a smaller size, along with the other default fastai augmentations provided by `aug_transforms`. We'll start out with small resized images, since we want to be able to iterate quickly:","metadata":{}},{"cell_type":"code","source":"dls = ImageDataLoaders.from_folder(trn_path, \n                                   valid_pct=0.2,  # dls contains the validation set, make it easy to calc train and validation loss at the same time\n                                   item_tfms = Resize(480, method='squish'),  # resize every single item into 480x480\n                                   batch_tfms = aug_transforms(size=128, min_scale=0.75)  # randomly resize images to 128, with minimum keep portion to be 75%\n                                  )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:14:58.307042Z","iopub.execute_input":"2025-08-20T17:14:58.307304Z","iopub.status.idle":"2025-08-20T17:15:05.257501Z","shell.execute_reply.started":"2025-08-20T17:14:58.307281Z","shell.execute_reply":"2025-08-20T17:15:05.256716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dls.show_batch(max_n=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:15:41.251764Z","iopub.execute_input":"2025-08-20T17:15:41.252078Z","iopub.status.idle":"2025-08-20T17:15:42.694618Z","shell.execute_reply.started":"2025-08-20T17:15:41.252038Z","shell.execute_reply":"2025-08-20T17:15:42.693759Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Our first model","metadata":{}},{"cell_type":"markdown","source":"Let's create a model. To pick an architecture, we should look at the options in [The best vision models for fine-tuning](https://www.kaggle.com/code/jhoward/the-best-vision-models-for-fine-tuning). I like the looks of `resnet26d`, which is the fastest resolution-independent model which gets into the top-15 lists there.\n\n3-step:\n1. feed the train/valid set `dls` to a vision_learner with vision model `resnet26d`\n2. find the best learning rate for the vision_learner\n3. use the learning rate to fine tune the vision_learner in step 1\n\nQuestion: what does fine tune do with learning rate?\n\nThought process: \n1. vision_learner is a pre-trained Neural Net + paddy data, this vision_learner should be able to predict the test set with a loss denoted as `loss_1`\n2. And then we find the learning_rate that can minimize this loss in the fastest way, let's name this `loss_ideal`.\n3. Then we feed the learning_rate to vision_learner (a NN) that changes the paramaters of the NN in the way that it descrease the `loss_1` towards `loss_ideal`\n\nIn classification problem, the loss is cross-entropy. (CrossEntropyLossFlat)","metadata":{}},{"cell_type":"code","source":"import torch, gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T18:38:34.863735Z","iopub.execute_input":"2025-08-20T18:38:34.864560Z","iopub.status.idle":"2025-08-20T18:38:35.343217Z","shell.execute_reply.started":"2025-08-20T18:38:34.864510Z","shell.execute_reply":"2025-08-20T18:38:35.342509Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"learn = vision_learner(dls, 'resnet26d', metrics=error_rate, path='.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T18:38:39.612211Z","iopub.execute_input":"2025-08-20T18:38:39.612498Z","iopub.status.idle":"2025-08-20T18:38:40.156541Z","shell.execute_reply.started":"2025-08-20T18:38:39.612474Z","shell.execute_reply":"2025-08-20T18:38:40.155792Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's try `fit_one_cycle` first:","metadata":{}},{"cell_type":"code","source":"learn.fit_one_cycle(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T18:39:07.157109Z","iopub.execute_input":"2025-08-20T18:39:07.157873Z","iopub.status.idle":"2025-08-20T18:43:01.086293Z","shell.execute_reply.started":"2025-08-20T18:39:07.157840Z","shell.execute_reply":"2025-08-20T18:43:01.085449Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"![read output](https://github.com/anna4fun/learning_notes_practical_deep_learning_courses/blob/main/Kaggle_jupyterNB/paddy_disease_classification/how_to_read_output_of_fit_one_cycle.png)","metadata":{}},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T19:02:57.411541Z","iopub.execute_input":"2025-08-20T19:02:57.412377Z","iopub.status.idle":"2025-08-20T19:02:57.755795Z","shell.execute_reply.started":"2025-08-20T19:02:57.412340Z","shell.execute_reply":"2025-08-20T19:02:57.755087Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The original notebook has `learn.to_fp16()` and that would crash when running the learning rate finders. I am changing to `to_fp32()` and avoid the crash.","metadata":{}},{"cell_type":"code","source":"learn.to_fp32()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T19:02:59.485724Z","iopub.execute_input":"2025-08-20T19:02:59.485975Z","iopub.status.idle":"2025-08-20T19:02:59.491284Z","shell.execute_reply.started":"2025-08-20T19:02:59.485957Z","shell.execute_reply":"2025-08-20T19:02:59.490608Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's see what the learning rate finder shows:\n\ny axis is the loss, x axis shows the corresponding learning rate. The minimum of loss correspond to learning_rate = 0.1, so I will use this minimum loss learning rate first, see if it causes overfitting.","metadata":{}},{"cell_type":"code","source":"learn.lr_find(suggest_funcs=(valley, slide, minimum))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T19:03:03.682402Z","iopub.execute_input":"2025-08-20T19:03:03.682688Z","iopub.status.idle":"2025-08-20T19:03:30.660194Z","shell.execute_reply.started":"2025-08-20T19:03:03.682666Z","shell.execute_reply":"2025-08-20T19:03:30.659312Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"`lr_find` generally recommends rather conservative learning rates, to ensure that your model will train successfully. I generally like to push it a bit higher if I can. Let's train a few epochs and see how it looks:\n\nlearn.fine_tune() \n```\nLearner.fine_tune (epochs, base_lr=0.002, freeze_epochs=1, lr_mult=100,\n                    pct_start=0.3, div=5.0, lr_max=None,\n                    div_final=100000.0, wd=None, moms=None, cbs=None,\n                    reset_opt=False, start_epoch=0)\nFine tune with Learner.freeze for freeze_epochs, then with Learner.unfreeze for epochs, using discriminative LR.\n```","metadata":{}},{"cell_type":"code","source":"learn.fine_tune(3, 0.0005)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T19:04:51.067239Z","iopub.execute_input":"2025-08-20T19:04:51.067890Z","iopub.status.idle":"2025-08-20T19:07:59.212951Z","shell.execute_reply.started":"2025-08-20T19:04:51.067861Z","shell.execute_reply":"2025-08-20T19:07:59.212086Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"My interpretation:\n1. train loss, valid loss, error rate all decrease monotonically, not indicating overfitting\n2. time to train each epoch on average is 46.5 seconds, which is not bad\n\n\nNoted that the loss here is cross-entropy loss, which is used for optimizing a classification problem. Error rate is the reportin metrics.","metadata":{}},{"cell_type":"markdown","source":"Difference between `fit_one_cycle` and `fine_tune`:\nThey reach to the same ends.fine_tune is a particular combination of fit_one_cycle(s) + (un)freeze(s), that works well in a lot (if not most) situations.\n\ndiscussion: https://forums.fast.ai/t/fine-tune-vs-fit-one-cycle/66029\n\nchatgpt answer:\n![difference](https://github.com/anna4fun/learning_notes_practical_deep_learning_courses/blob/main/Kaggle_jupyterNB/paddy_disease_classification/difference_between_fit_one_cycle_AND_fine_tune.png)","metadata":{}},{"cell_type":"markdown","source":"We're now ready to build our first submission. Let's take a look at the sample Kaggle provided to see what it needs to look like:","metadata":{}},{"cell_type":"markdown","source":"## Submitting to Kaggle","metadata":{}},{"cell_type":"code","source":"ss = pd.read_csv(path/'sample_submission.csv')\nss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T19:08:14.617771Z","iopub.execute_input":"2025-08-20T19:08:14.618065Z","iopub.status.idle":"2025-08-20T19:08:14.634397Z","shell.execute_reply.started":"2025-08-20T19:08:14.618036Z","shell.execute_reply":"2025-08-20T19:08:14.633697Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"OK so we need a CSV containing all the test images, in alphabetical order, and the predicted label for each one. We can create the needed test set using fastai like so:","metadata":{}},{"cell_type":"code","source":"tst_files = get_image_files(path/'test_images').sorted()\ntst_dl = dls.test_dl(tst_files)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T19:09:49.618909Z","iopub.execute_input":"2025-08-20T19:09:49.619205Z","iopub.status.idle":"2025-08-20T19:09:52.477461Z","shell.execute_reply.started":"2025-08-20T19:09:49.619181Z","shell.execute_reply":"2025-08-20T19:09:52.476759Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can now get the probabilities of each class, and the index of the most likely class, from this test set (the 2nd thing returned by `get_preds` are the targets, which are blank for a test set, so we discard them):","metadata":{}},{"cell_type":"code","source":"probs,_,idxs = learn.get_preds(dl=tst_dl, with_decoded=True)\nidxs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T19:09:55.550560Z","iopub.execute_input":"2025-08-20T19:09:55.550832Z","iopub.status.idle":"2025-08-20T19:10:10.418992Z","shell.execute_reply.started":"2025-08-20T19:09:55.550811Z","shell.execute_reply":"2025-08-20T19:10:10.418129Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"These need to be mapped to the names of each of these diseases, these names are stored by fastai automatically in the `vocab`:","metadata":{}},{"cell_type":"code","source":"dls.vocab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:53:47.463949Z","iopub.execute_input":"2025-08-20T17:53:47.464902Z","iopub.status.idle":"2025-08-20T17:53:47.471125Z","shell.execute_reply.started":"2025-08-20T17:53:47.464860Z","shell.execute_reply":"2025-08-20T17:53:47.470372Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can create an apply this mapping using pandas:","metadata":{}},{"cell_type":"code","source":"mapping = dict(enumerate(dls.vocab))\nresults = pd.Series(idxs.numpy(), name=\"idxs\").map(mapping) # in pandas, mapping a dictionary is super fast\nresults","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T19:10:27.963528Z","iopub.execute_input":"2025-08-20T19:10:27.964492Z","iopub.status.idle":"2025-08-20T19:10:27.975531Z","shell.execute_reply.started":"2025-08-20T19:10:27.964451Z","shell.execute_reply":"2025-08-20T19:10:27.974820Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Kaggle expects the submission as a CSV file, so let's save it, and check the first few lines:","metadata":{}},{"cell_type":"code","source":"ss['label'] = results\nss.to_csv('submission.csv', index=False)\n!head submission.csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T19:10:53.714979Z","iopub.execute_input":"2025-08-20T19:10:53.715252Z","iopub.status.idle":"2025-08-20T19:10:53.878567Z","shell.execute_reply.started":"2025-08-20T19:10:53.715232Z","shell.execute_reply":"2025-08-20T19:10:53.877624Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's submit this to kaggle. We can do it from the notebook if we're running on Kaggle, otherwise we can use the API:","metadata":{}},{"cell_type":"code","source":"if not iskaggle:\n    from kaggle import api\n    api.competition_submit_cli('subm.csv', 'initial rn26d 128px', comp)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T18:11:38.756451Z","iopub.execute_input":"2025-08-20T18:11:38.756756Z","iopub.status.idle":"2025-08-20T18:11:38.761178Z","shell.execute_reply.started":"2025-08-20T18:11:38.756729Z","shell.execute_reply":"2025-08-20T18:11:38.760421Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Success! We successfully created a submission.","metadata":{}},{"cell_type":"markdown","source":"## Conclusion","metadata":{}},{"cell_type":"markdown","source":"Our initial submission is not very good (top 80% of teams) but it only took a minute to train. The important thing is that we have a good starting point to iterate from, and we can do rapid iterations. Every step from loading the data to creating the model to submitting to Kaggle is all automated and runs quickly.\n\nTherefore, we can now try lots of things quickly and easily and use those experiments to improve our results. In the next notebook, we'll do exactly that! So if you're ready, take a look at [part 2 of the series](https://www.kaggle.com/code/jhoward/small-models-road-to-the-top-part-2/).\n\nIf you found this notebook useful, please remember to click the little up-arrow at the top to upvote it, since I like to know when people have found my work useful, and it helps others find it too. And if you have any questions or comments, please pop them below -- I read every comment I receive!","metadata":{}},{"cell_type":"markdown","source":"## Addendum","metadata":{}},{"cell_type":"markdown","source":"`fastkaggle` also provides a function that pushes a notebook to Kaggle Notebooks. I wrote this notebook on my own machine, and pushed it to Kaggle from there -- here's the command I used:","metadata":{}},{"cell_type":"code","source":"if not iskaggle:\n    push_notebook('jhoward', 'first-steps-road-to-the-top-part-1',\n                  title='First Steps: Road to the Top, Part 1',\n                  file='first-steps-road-to-the-top-part-1.ipynb',\n                  competition=comp, private=False, gpu=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}